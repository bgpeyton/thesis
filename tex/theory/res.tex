\section{Response theory} \label{se:res}
Response theory combines adiabatic perturbation theory with a Fourier transform of the 
time-dependent equations into the frequency domain\cite{Pederson2020}. The prediction of the response 
of molecular systems to an electromagnetic field (EMF) has important applications in organic synthesis and
characterization. To explore these effects, we may relate properties to a perturbative expansion of a 
total electric or magnetic moment, from which response tensors related to a host of properties may be defined. 
These response tensors generally take the form of products of ground- and excited-state transition moments of 
the electric or magnetic dipole operator. In this chapter we will summarize the derivation of these 
response tensors and their relationships to field-induced molecular phenomena. We then present a method 
for obtaining these tensors through Fourier transform of a time-dependent ``Quasi-energy'' which is 
rigorously defined in the context of electronic structure theory, providing working equations for 
predicting molecular responses to EMF using approximate wave function-based theory.

\subsection{Exact Response} \label{ss:exact}
Under classical electrodynamics, the potential energy $V$ of a system of charges in a static electric field 
may be written in a multipole expansion:

\begin{equation} \label{eq:pot_V}
V = q(\phi)_0 - \mu_\alpha(E_\alpha)_0 - \frac{1}{3}\Theta_{\alpha\beta}(E_{\alpha\beta})_0 + \ldots
\end{equation}
with the scalar potential $\phi$, the cartesian component $\alpha$ of the electric field $E_\alpha$, and the electric field gradient with respect to two cartesian coordinates $E_{\alpha\beta}$. Here we have defined the multipoles as the electric monopole or charge $q$, the electric dipole $\mu_\alpha$, and the electric quadrupole $\Theta_{\alpha\beta}$. The subscript $0$ indicates that the potential, field, or gradient is taken at the system origin.

We may also expand the potential in a Taylor series about the zero-field potential:
\begin{equation} \label{eq:tay_V}
    V[E_0] = V_0 + (E_\alpha)_0\frac{\partial V}{\partial (E_\alpha)_0} + \frac{1}{2}(E_\alpha)_0(E_\beta)_0\frac{\partial V^2}{\partial (E_\alpha) \partial (E_\beta)} + \ldots
\end{equation}

From Eq.~(\ref{eq:pot_V}), we see that a cartesian component of the electric dipole may be written as the derivative of the potential with respect to the field, 
\begin{equation} \label{eq:mu_part}
    \mu_\alpha = -\frac{\partial V}{\partial (E_\alpha)_0}.
\end{equation}
By comparing Eqs.~(\ref{eq:tay_V}) and (\ref{eq:mu_part}), we see that the total electric dipole may be re-written 
\begin{equation} \label{eq:mu_tot}
\mu_\alpha = \mu_{0\alpha} + \alpha_{\alpha\beta}(E_\beta)_0 + \frac{1}{2}\beta_{\alpha\beta\gamma}(E_\beta)_0(E_\gamma)_0 + \ldots
\end{equation}
where we have defined the response tensors for the permanent (field-independent) dipole moment $\mu_{0\alpha}$, electric polarizability $\alpha_{\alpha\beta}$, first electric hyperpolarizability $\beta_{\alpha\beta\gamma}$, and higher order terms as higher-order derivatives of the potential, \textit{viz.}
\begin{subequations} \label{eq:derivs}
    \begin{equation} \label{eq:mu_0}
    \mu_{0\alpha} = -\frac{\partial V}{\partial (E_\alpha)_0}
    \end{equation}

    \begin{equation} \label{eq:alpha}
    \alpha_{\alpha\beta} = -\frac{\partial^2 V}{\partial (E_\alpha)_0 \partial (E_\beta)_0}
    \end{equation}

    \begin{equation} \label{eq:beta}
    \beta_{\alpha\beta\gamma} = -\frac{\partial^3 V}{\partial (E_\alpha)_0 \partial (E_\beta)_0 \partial (E_\gamma)_0}.
    \end{equation}
\end{subequations}
Property tensors for magnetic and mixed electric-magnetic properties are defined in an analogous manner. 

Quantum mechanical expressions for the property tensors may be obtained through perturbation theory. 
For static-field properties, this process is straightforward, and expressions similar to those found for
correlation energy corrections in ~Eq.({\ref{eq:E2}) arise in the perturbative expansion of the time-independent Schr\"odinger
equation, e.g., for the static polarizability tensor:
\begin{equation} \label{eq:static_pol}
\alpha_{\alpha\beta} = -2\sum_{j\neq n}\frac{\bra{n}\mu_\alpha\ket{j}\bra{j}\mu_\beta\ket{n}}{V_n - V_j} 
\end{equation}
where the sum runs over excited states $j$ and $n$.

Of more practical application is the prediction of dynamic-field properties, such as dynamic polarizabilities, 
optical rotation, and circular dichroism (which are the primary targets of [PAPER1] and [PAPER3]).
For these and other time-dependent response properties, some description of the time evolution of the wave function is
required. 
These properties may be solved directly from the time-dependent analogue of ~Eq.(\ref{eq:mu_tot}). 
To compute the dynamic dipole, one must compute the dipole moment expectation value of a system in the presence of an explicitly
time-dependent electric field.
Fourier transforming the dynamic dipole into the frequency domain would produce broadband spectra.
However, explicit time propagation of the wave function is exceedingly expensive. This is the topic of chapters [TDCC] and [PAPER 3]. 
For now, we will consider an alternative approach which computes properties at individual frequencies, 
but does not require explicit propagation of the wave function. 

Beginning from the time-dependent Schr\"odinger equation,
\begin{equation} \label{eq:tdse}
    \hat{H}(t)\ket{\Psi(t)} = i\hbar\partt{}\ket{\Psi(t)}
\end{equation}
we will, without loss of generality, assume a time-dependent wave function expansion of the form
\begin{subequations} \label{eq:td_wfn}
    \begin{equation}
        \ket{\Psi(t)} = d_n(t)\ket{\psi(t)}
    \end{equation}
    \begin{equation}
        \ket{\psi(t)} = e^{-iE_nt/\hbar}\ket{n}
    \end{equation}
\end{subequations}
where $\ket{\psi(t)}$ is an approximate wave function consisting of a set of known, time-independent functions $\ket{n}$
and an exponentiated phase. Expressing the Hamiltonian as in ~Eq{(\ref{eq:H}) as a sum of the time-independent molecular
Hamiltonian $\hat{H}^{(0)}$ with a time-dependent perturbation $\hat{V}(t)$
(generally taken to be an EMF) and inserting this and the wave function expansion into ~Eq.({\ref{eq:tdse}) yields
\begin{equation} \label{eq:sub_tdse}
    (\hat{H}^{(0)} + \hat{V}(t))d_n(t)e^{-iE_nt/\hbar}\ket{n} = i\hbar \partt{}[d_n(t)e^{-iE_nt/\hbar}]\ket{n}.
\end{equation}
It should be noted that, in the absence of a perturbation (time $t = 0$), this reduces to the time-independent Schr\"odinger equation ($d_n(0) = 1$). Using the chain rule, ~Eq.({\ref{eq:sub_tdse}}) becomes  
\begin{equation} \label{eq:chain_tdse}
    (\hat{H}^{(0)} + \hat{V}(t))d_n(t)e^{-iE_nt/\hbar}\ket{n} = [E_n d_n(t) + i\hbar \partt{d_n(t)}]e^{-iE_nt/\hbar}\ket{n}.
\end{equation}
If we assume we have \textit{exact} eigenstates $\ket{n}$ of the molecular Hamiltonian, \textit{i.e.} exact ground and excited state wave functions, then the second terms of both sides of ~Eq.(\ref{eq:chain_tdse}) cancel. Projecting on the left by 
excited states $\bra{m}$ (which contains only one state nonorthogonal to $\ket{n}$ and thus collapses the sum on the 
right-hand side) and rearranging, we arrive at the differential equation
\begin{equation} \label{eq:diffeq}
    \partt{d_m(t)} = \frac{1}{i\hbar}\bra{m}\hat{V}(t)\ket{n}d_n(t)e^{i\omega_{mn} t}
\end{equation}
which describes the time evolution of the wave function coefficient $d_m(t)$. We have also introduced the angular 
frequency $\omega_{mn} = (E_m - E_n)/\hbar$. 

Integration of ~Eq.(\ref{eq:diffeq}) from time $t' = 0$ to $t' = t$ yields a recursive equation for the 
wave function parameter $d_m(t)$, due to the presence of $d_n(t)$ on the right-hand side. 
However, as a consequence of our assumption that the system begins in its unperturbed ground state, all
coefficients at $t' = 0$ reduce to $\delta_{m,0}$. To linear order in $\hat{V}$, ~Eq.(\ref{eq:diffeq}) may be written
\begin{equation} \label{eq:irt}
    d_m(t') = \frac{1}{i\hbar}\int_0^t\bra{m}\hat{V}(t^{'})\ket{0}e^{i\omega_{m0}t^{'}}dt^{'}.
\end{equation}
%\begin{equation} \label{eq:irt}
%    \begin{aligned}
%    d_m(t') = 1 &+ \frac{1}{i\hbar}\int_0^t\bra{m}\hat{V}(t^{'})\ket{n}d_n(t^{'})e^{-i\omega_{mn}t^{'}}dt^{'} \\
%            = 1 &+ \frac{1}{i\hbar}\int_0^t\bra{m}\hat{V}(t^{'})\ket{n}e^{-i\omega_{mn}t^{'}}dt^{'} \\
%                &- \frac{1}{\hbar}\int_0^t\int_0^{t^{'}}\bra{m}\hat{V}(t^{'})\ket{l}\bra{l}\hat{V}(t^{''})\ket{n}e^{-i\omega_{ml}t^{'}}e^{-i\omega_{ln}t^{''}}dt^{''} \\
%                &+ \ldots
%    \end{aligned}
%\end{equation}

To continue, we choose our perturbation to be a simple, time-dependent field at a given frequency $\omega$ 
\begin{equation} \label{eq:field}
\hat{V}(t) = \hat{v}^\omega_\alpha F^\omega_\alpha e^{-i\omega t}
\end{equation}
with field strength $F^\omega_\alpha$ and arbitrary field operator $\hat{v}^\omega_\alpha$, such as the electric or magnetic dipole operator. 
Note that the implicit summation runs over both $\omega$ and $\alpha$, and the sum in ~Eq.(\ref{eq:irt}) runs over excited states $\ket{m}$.
Finally, inserting ~Eq.(\ref{eq:field}) into ~Eq.(\ref{eq:irt}) and integrating, we arrive at the final expression for the
wave function parameters
\begin{equation} \label{eq:sot}
    \begin{aligned}
        d_m(t) = \frac{1}{\hbar}\frac{\bra{m}\hat{v}^\omega_\alpha\ket{0}e^{i(\omega_{m0}-\omega)t}}{\hbar(\omega_{m0}-\omega)}F^{\omega}_{\alpha}.
%        d_m(t') = 1 &+ \frac{-1}{\hbar}\frac{\bra{m}\hat{v}^\omega_\alpha\ket{n}}{\omega_{mn} - \omega_1}e^{-i\omega_{mn}t}e^{-i\omega_1t} \\
%                &- \frac{1}{\hbar}\frac{\bra{m}\hat{v}^{\omega1}_\alpha\ket{l}\bra{l}\hat{v}^{\omega2}_\beta\ket{n}}{(\omega_{ml}-\omega_1)(\omega_{ln}-\omega_2)}e^{-i(\omega_{ml}-\omega_{ln})t}e^{-i(\omega_1-\omega_2)t} \\
%                &+ \ldots
    \end{aligned}
\end{equation}
 
To arrive at a dipole expression in the form of ~Eq.(\ref{eq:mu_tot}), we may compute the expectation 
value of the electric dipole operator $\hat{\mu}$. After rearrangement, we arrive at
\begin{equation} \label{eq:sos}
    \begin{aligned}
    \bra{\Psi(t)}\hat\mu\ket{\Psi(t)} &= \bra{0}\hat\mu\ket{0} \\ 
    &- \sum_{m\neq0}[\frac{\bra{m}\hat\mu\ket{0}\bra{0}\hat{v}^\omega_\alpha\ket{m}}{\hbar(\omega_{mo}+\omega)}
        + \frac{\bra{0}\hat\mu\ket{m}\bra{m}\hat{v}^\omega_\alpha\ket{0}}{\hbar(\omega_{mo}-\omega)}]
    e^{-i\omega t}F^\omega_\alpha
    \end{aligned}
\end{equation}
where we have truncated at the linear response function of $\hat{\mu}$ perturbed by $\hat{V}(t)$. This is known as the \textit{exact} linear response function. In general, 
response functions can be identified by the expansion of an operator $\hat\Omega$:
\begin{equation}
    \begin{aligned}
    \bra{\Psi(t)}\hat\Omega\ket{\Psi(t)} &= \bra{0}\hat\Omega\ket{0} \\ 
    &+ \linresp{\hat\Omega}{\hat{v}^{\omega_1}_\alpha}e^{-i\omega_1 t}F^{\omega_1}_\alpha \\ 
    &+ \quadresp{\hat\Omega}{\hat{v}^{\omega_1}_\alpha}{\hat{v}^{\omega_2}_\beta}e^{-i(\omega_1+\omega_2)t}F^{\omega_1}_\alpha F^{\omega_2}_\beta \\
    &+ \ldots
    \end{aligned}
\end{equation}
where we have introduced notation for the linear $\linresp{\hat\Omega}{\hat{v}^{\omega_1}_\alpha}$, 
quadratic $\quadresp{\hat\Omega}{\hat{v}^{\omega_1}_\alpha}{\hat{v}^{\omega_2}_\beta}$, and higher-order response functions.

\subsection{Approximate Response} \label{ss:apprx}
Sum-over-states expressions like those in Eq.~(\ref{eq:sos}) can be solved by computing the excited state wave functions and 
summing their individual contributions to the property. This poses a unique challenge in that the response tensor is not a product 
of only one targeted excited state, but of all possible excited states. 
While it is expected many high-energy states will have negligible contributions, the number of states 
required to accurately model these properties makes this approach prohibitively expensive for excited-
state extensions to ground-state  methods, such as equation-of-motion (EOM) CC. We can avoid this 
problem by building response equations based on approximate ground-state wave functions, such as ~Eq.(\ref{eq:cc_TISE}).
This eliminates the ability to compute excited-state wave functions, but allows us to replace the sum-over-states 
expression with a set of coupled linear equations which are far more computationally tractable.

Beginning with a time-dependent wave function $\ket{\Psi(t)}$, we may separate this into two time-dependent pieces - the exponential of a phase factor $\phi(t)$, and a phase-isolated wave function $\ket{\piw}$:
\begin{equation} \label{total_psi}
    \ket{\Psi(t)} = e^{-i\phi(t)}\ket{\piw}.
\end{equation}
We may require that the phase of the projection of $\ket{\piw}$ onto the ground-state wave function be 
zero - in other words, in the limit of zero time-dependent perturbation, $\ket{\piw}$ reduces to the
ground state wave function. This is analogous to our approach in ~Eq.(\ref{eq:td_wfn}), where our focus has
now shifted from the wave function parameters to the phase factor.
Inserting these definitions into the time-dependent Schr\"odinger equation,
we arrive at Eq.~(\ref{eq:quasi_schro}):
\begin{equation} \label{eq:quasi_schro}
    (\hat{H} - i\hbar \partt{})\ket{\piw} = Q(t)\ket{\piw}
\end{equation}
where we have defined the time-dependent quasi-energy as the reduced Planck constant times the derivative
of the phase factor,
\begin{equation} \label{eq:quasi_e}
    Q(t) = \hbar\partt{\phi(t)}.
\end{equation}
It is important to note that, just as the phase-isolated wave function reduces to the ground state wave function in the absence of a perturbation, the quasi-energy also reduces to the ground state energy in this case. 

It can be shown that the quasi-energy is manifestly real, and both a time-dependent variational principle and Hellmann-Feynman theorem apply. To obtain a time-independent quantity to perturbatively expand, the quasi-energy is integrated over time to form the time-averaged quasi-energy $Q_T$. The variational and Hellmann-Feynman theorems can then be written
\begin{equation} \label{eq:var}
    \partial Q_T = 0
\end{equation}
and
\begin{equation} \label{eq:hf-theorem}
    \frac{dQ_T}{d\hat\Omega} = \frac{1}{T}\int_{t^{'}}^{t^{'}+T}\bra{\piw}\frac{\partial \hat{H}}{\partial\hat\Omega}\ket{\piw}dt^{'},
\end{equation}
respectively, for an arbitrary perturbation $\hat\Omega$ (usually taken to be an electromagnetic field).

In the preceding derivation, at no point was it assumed that we have \textit{exact} eigenfunctions of the time-independent 
Hamiltonian. Thus, the above equations are valid for approximate ground-state theories, such as CC. We may now define
our approximate response functions as we did in ~Eq.(\ref{eq:derivs}) as derivatives of this time-averaged Quasi-energy,
\begin{subequations}
    \begin{equation}
        \linresp{\hat\Omega}{\hat v^{\omega_1}_{\alpha}} = \frac{d^2Q_T}{d\hat\Omega dF^{\omega_1}_\alpha}
    \end{equation}
    \begin{equation}
        \quadresp{\hat\Omega}{\hat{v}^{\omega_1}_\alpha}{\hat{v}^{\omega_2}_\beta} = \frac{d^3Q_T}{d\hat\Omega dF^{\omega_1}_\alpha dF^{\omega_2}_\beta}
    \end{equation}
\end{subequations}
and working equations may be derived by inserting the specific approximate wave function ansatz.

The response functions of interest to the present work are the linear response functions between 
the electric dipole and an electric field
$\linresp{\hat\mu}{\hat{\mu}}$,
and the magnetic dipole in an electric field
$\linresp{\hat m}{\hat{\mu}}$. 
These are responsible for the dynamic electric polarizability and chiroptical response (optical
rotation and circular dichroism) respectively. The latter constitutes a long-standing challenge
for response theory, requiring mixed electric- and magnetic-field derivatives and minimal room
for error, but is also a 
prime candidate for comparisons to experiment. Some limitations of and alternatives to response
theory will be explored in chapters [PAPER 1] and [PAPER 3].
