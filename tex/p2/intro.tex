%introduction.tex%
\section{Introduction} \label{intro}

Machine-learning (ML) has been applied to a number of chemical applications, with excellent (and current) surveys of the field published in 2019\cite{Haghighatlari2019a,Elton2019}. While applications in high-throughput chemical screening using computationally ``free'' descriptors of molecular systems (e.g. the molecular formula or graph) have been fruitful\cite{}, recently much work has been focused on machine-learning quantum mechanics (MLQM)\cite{}. These methods generally apply machine-learning to either replace or bolster the often expensive algorithms used in quantum mechanics for solving the electronic Schr\"{o}dinger equation. 
Schemes for ML-assisted models include learning force-fields or other parameterizations from \textit{ab initio} data\cite{Sauceda2019,Galvelis2019}, improved guesses for e.g. important contributions to configuration-interaction space\cite{Coe2018} or amplitudes in coupled cluster (CC) theory\cite{Townsend2019}, and direct energy or property prediction using mean-field, correlated, or density-functional-based approaches\cite{Welborn2018a,Cheng2019,Yuan2019,Wilkins2019,Smitha}. 

The focus of this work will be on the bolstering of wave function-based methods, such as CC theory\cite{Crawford2000} and many-body perturbation theory (MBPT)\cite{Coester1960a,Bartlett1981}, for predicting energies and properties across potential energy surfaces or molecular dynamics (MD) trajectories. 
This is an application also covered by recent work facilitating ML for forces in \textit{ab initio} MD\cite{Chmiela2018}, fast numerical gradients for geometry optimization\cite{Schmitz2018a}, and general-purpose local potential energy surfaces (PESs)\cite{Abbott}. Note, however, that these methodologies may be extended to other applications, such as learning of the wave function itself and predicting properties across large chemical datasets as described in Refs.~\citenum{Schutt2019} and~\citenum{Christensen2019}, respectively.  

There has also been some recent interest in alternative, wave function-based representations (as opposed to the more common representations based on the molecular structure), which in principle have several advantages. In particular, we define three desirable properties: 
first, representations derived from increasingly accurate electronic structure methods should provide more faithful representations of the wave function, resulting in more accurate and efficient ML. 
This rules out features that are not systematically improvable, such as the Hartree-Fock wave function parameters used by Miller and co.\cite{Welborn2018a,Cheng2019} 
Second, the representation should be of reasonable size to be stored for thousands of molecules, with the possibility of reducing their size for extremely large datasets. This rules out a real space representation of the electron density on a grid\cite{Snyder2012}.
Third, a solid theoretical motivation for the representation should be given, with simple mappings from representation to target preferred. 
This third point is critical, as we will show that the relationship between the electronic wave function (specifically, the corresponding density matrix) and properties expressed as expectation values of one- and two-electron operators suggests a clear recipe for a wave function representation which is appropriate for machine-learning any molecular response property. 

One such wave function-based representation is the t-amplitude tensor representation (TATR) introduced by Margraf and Reuter\cite{Margraf2018}. This representation is based on CC or MP2 amplitudes, paired with the many-body tensor representation (MBTR) formalism\cite{Rupp2018}. Using the TATR, it was shown that the CC correlation energies of a series of diatomics can be predicted with chemical accuracy ($\sim$1 kcal/mol) across the full potential energy surface with only 12 training points. This representation adheres to the three criteria above: amplitudes from increasingly accurate electronic structure methods should provide increasingly accurate TATRs, these amplitudes can be cut-off and stored based solely on their magnitude (as evidenced by retaining only 150 amplitudes for the diatomic representations in Ref.~\citenum{Margraf2018}), and the relationship between wave function amplitudes and the target function (the correlation energy) is well-defined. 

Indeed, the electronic wave function, in principle, gives access to any molecular property. The derivation of arbitrary properties in terms of wave function amplitudes is far from straightforward, however. 
In order to generalize the mapping from representation to target function (i.e. arbitrary molecular properties), we propose the density tensor representation (DTR), an analogous extension of the MBTR using one- and two-particle reduced density matrices rather than wave function amplitudes. 
In the following sections we demonstrate that careful choice of the underlying raw wave function features, as laid out in section~\ref{est}, results in a more compact representation with a simple theoretical motivation. 
A proof-of principle ML model using this representation is detailed in section~\ref{ml}. 
Results from this initial implementation for electronic energies and dipole moments of several small molecules are given in sections~\ref{cutoffs} -~\ref{dip}, and details of their possible extensions for molecular transferability and arbitrary property calculations given in section~\ref{ext}.
